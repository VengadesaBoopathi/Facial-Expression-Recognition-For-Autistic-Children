{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Set the paths for training and testing data\ntrain_data_dir = '/kaggle/input/autistic-children-emotions-dr-fatma-m-talaat/Autistic Children Emotions - Dr. Fatma M. Talaat/Train'\ntest_data_dir = '/kaggle/input/autistic-children-emotions-dr-fatma-m-talaat/Autistic Children Emotions - Dr. Fatma M. Talaat/Test'\n\n# Define image size and batch size\nimg_size = (48, 48)\nbatch_size = 25\n\n# Data augmentation for training\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    validation_split=0.2\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-06T03:23:46.536979Z","iopub.execute_input":"2024-06-06T03:23:46.537447Z","iopub.status.idle":"2024-06-06T03:24:00.742001Z","shell.execute_reply.started":"2024-06-06T03:23:46.537411Z","shell.execute_reply":"2024-06-06T03:24:00.740833Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"2024-06-06 03:23:48.747450: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-06 03:23:48.747572: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-06 03:23:48.914208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load training data\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\n\n# Load validation data\nvalidation_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation'\n)\n\n# Load test data\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical'\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:24:24.728936Z","iopub.execute_input":"2024-06-06T03:24:24.729685Z","iopub.status.idle":"2024-06-06T03:24:24.970393Z","shell.execute_reply.started":"2024-06-06T03:24:24.729649Z","shell.execute_reply":"2024-06-06T03:24:24.969312Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 608 images belonging to 6 classes.\nFound 150 images belonging to 6 classes.\nFound 75 images belonging to 6 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use pre-trained VGG16 model without the top layer\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n\n# Freeze the layers of the pre-trained model\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Create a new model on top of the pre-trained model\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(len(train_generator.class_indices), activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:24:50.912669Z","iopub.execute_input":"2024-06-06T03:24:50.913048Z","iopub.status.idle":"2024-06-06T03:24:55.184064Z","shell.execute_reply.started":"2024-06-06T03:24:50.913014Z","shell.execute_reply":"2024-06-06T03:24:55.183137Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"# Compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Train the model\nmodel.fit(\n    train_generator,\n    epochs=10,\n    validation_data=validation_generator\n)\n\n# Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(test_generator)\nprint(f'Test accuracy: {test_acc}')","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:27:18.589181Z","iopub.execute_input":"2024-06-06T03:27:18.589587Z","iopub.status.idle":"2024-06-06T03:29:12.643584Z","shell.execute_reply.started":"2024-06-06T03:27:18.589557Z","shell.execute_reply":"2024-06-06T03:29:12.642497Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 401ms/step - accuracy: 0.0939 - loss: 2.4380 - val_accuracy: 0.4000 - val_loss: 1.5760\nEpoch 2/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 381ms/step - accuracy: 0.3212 - loss: 1.7171 - val_accuracy: 0.4667 - val_loss: 1.4943\nEpoch 3/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 372ms/step - accuracy: 0.3977 - loss: 1.5648 - val_accuracy: 0.4333 - val_loss: 1.4640\nEpoch 4/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 365ms/step - accuracy: 0.3701 - loss: 1.6680 - val_accuracy: 0.4467 - val_loss: 1.4686\nEpoch 5/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 364ms/step - accuracy: 0.4123 - loss: 1.5607 - val_accuracy: 0.4533 - val_loss: 1.4651\nEpoch 6/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 377ms/step - accuracy: 0.4011 - loss: 1.5082 - val_accuracy: 0.4800 - val_loss: 1.4517\nEpoch 7/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 361ms/step - accuracy: 0.4398 - loss: 1.5480 - val_accuracy: 0.4600 - val_loss: 1.4598\nEpoch 8/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 361ms/step - accuracy: 0.4156 - loss: 1.5151 - val_accuracy: 0.4600 - val_loss: 1.4536\nEpoch 9/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 381ms/step - accuracy: 0.4199 - loss: 1.5005 - val_accuracy: 0.4600 - val_loss: 1.4457\nEpoch 10/10\n\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 360ms/step - accuracy: 0.4480 - loss: 1.4791 - val_accuracy: 0.4400 - val_loss: 1.4236\n\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 318ms/step - accuracy: 0.5700 - loss: 1.3276\nTest accuracy: 0.5600000023841858\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom tensorflow.keras.preprocessing import image\n\n# Path to the image you want to test\nimage_path = '/kaggle/input/autistic-children-emotions-dr-fatma-m-talaat/Autistic Children Emotions - Dr. Fatma M. Talaat/Test/fear/13.jpg'\n\n# Load and preprocess the image\nimg = image.load_img(image_path, target_size=(48, 48))\nimg_array = image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array /= 255.0  # Normalize the pixel values to be between 0 and 1\n\n# Make predictions\npredictions = model.predict(img_array)\n\n# Get the emotion label with the highest probability\nemotion_labels = ['Surprise', 'Delight', 'Sadness', 'Fear', 'Joy', 'Anger']\npredicted_emotion = emotion_labels[np.argmax(predictions)]\n\n# Print the predicted emotion\nprint(f'The predicted emotion is: {predicted_emotion}')\n","metadata":{"execution":{"iopub.status.busy":"2024-06-06T03:29:18.604914Z","iopub.execute_input":"2024-06-06T03:29:18.605361Z","iopub.status.idle":"2024-06-06T03:29:18.893184Z","shell.execute_reply.started":"2024-06-06T03:29:18.605321Z","shell.execute_reply":"2024-06-06T03:29:18.891914Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step\nThe predicted emotion is: Fear\n","output_type":"stream"}]}]}